# xAI Grok Chatbot Integration

Este documento descreve a integra√ß√£o do chatbot com xAI Grok usando o AI SDK para streaming de respostas em tempo real.

## üöÄ Configura√ß√£o

### 1. Depend√™ncias

As seguintes depend√™ncias j√° est√£o instaladas no projeto:

```json
{
  "@ai-sdk/xai": "^1.0.0",
  "ai": "^4.0.0"
}
```

### 2. Vari√°veis de Ambiente

Configure as seguintes vari√°veis no arquivo `.env`:

```env
# Chatbot Configuration - xAI Grok
XAI_API_KEY=xai-your-actual-api-key-here
XAI_MODEL=grok-2-1212
XAI_MAX_TOKENS=8192
XAI_TEMPERATURE=0.1
```

### 3. Obter API Key do xAI

1. Acesse [console.x.ai](https://console.x.ai)
2. Fa√ßa login ou crie uma conta
3. Navegue para API Keys
4. Crie uma nova API key
5. Copie a key e adicione no arquivo `.env`

## üìÅ Arquivos Criados

### API Endpoint
- `/api/chatbot-stream.js` - Endpoint para streaming de respostas do Grok

### Componentes
- `/src/components/ChatbotWidgetStream.jsx` - Widget de chat com streaming
- `/src/components/examples/XAIChatbotExample.jsx` - Exemplo simples
- `/src/pages/ChatbotTestPage.jsx` - P√°gina de teste

## üîß Como Usar

### C√≥digo B√°sico

```javascript
import { xai } from "@ai-sdk/xai";
import { streamText } from "ai";

const result = await streamText({
  model: xai("grok-2-1212"),
  prompt: "Sua pergunta aqui",
});

for await (const textPart of result.textStream) {
  process.stdout.write(textPart);
}
```

### API Endpoint

```javascript
// /api/chatbot-stream.js
import { xai } from "@ai-sdk/xai";
import { streamText } from "ai";

export default async function handler(req, res) {
  const { message } = req.body;
  
  const model = xai(process.env.XAI_MODEL || "grok-2-1212");
  
  const result = await streamText({
    model: model,
    prompt: message,
    maxTokens: parseInt(process.env.XAI_MAX_TOKENS) || 1000,
    temperature: parseFloat(process.env.XAI_TEMPERATURE) || 0.1,
  });

  // Stream response
  for await (const textPart of result.textStream) {
    res.write(textPart);
  }
  
  res.end();
}
```

### Frontend Streaming

```javascript
const response = await fetch('/api/chatbot-stream', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ message: 'Ol√°!' }),
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value, { stream: true });
  console.log(chunk); // Texto sendo recebido em tempo real
}
```

## üß™ Teste

### P√°gina de Teste

Acesse `/chatbot-test` para testar a integra√ß√£o:

- Exemplo simples de chat
- Widget flutuante
- Demonstra√ß√£o de streaming
- Instru√ß√µes de configura√ß√£o

### Comandos de Teste

```bash
# Testar o chatbot
npm run test:chatbot

# Executar servidor de desenvolvimento
npm run dev

# Acessar p√°gina de teste
# http://localhost:3000/chatbot-test
```

## üéØ Caracter√≠sticas

### Streaming em Tempo Real
- Respostas aparecem conforme s√£o geradas
- Indicador visual de streaming
- Cancelamento de requisi√ß√µes

### Configura√ß√£o M√©dica
- Prompt especializado para cl√≠nica oftalmol√≥gica
- Informa√ß√µes da Cl√≠nica Saraiva Vision
- Diretrizes m√©dicas e de seguran√ßa
- Redirecionamento para agendamentos

### Interface Responsiva
- Widget flutuante
- Design mobile-friendly
- Acessibilidade completa
- A√ß√µes r√°pidas (WhatsApp, Agendamento)

## üîí Seguran√ßa

### Valida√ß√µes
- Valida√ß√£o de entrada de mensagens
- Limite de caracteres (1000)
- Rate limiting (configur√°vel)
- Sanitiza√ß√£o de dados

### Compliance M√©dico
- N√£o fornece diagn√≥sticos
- Direciona emerg√™ncias para atendimento presencial
- Mant√©m disclaimers m√©dicos
- Conformidade com CFM

## üìä Monitoramento

### M√©tricas
- Tempo de resposta
- Taxa de erro
- Uso de tokens
- Satisfa√ß√£o do usu√°rio

### Logs
- Todas as intera√ß√µes s√£o logadas
- Erros s√£o capturados
- Performance √© monitorada

## üöÄ Deploy

### Vercel
O projeto est√° configurado para deploy autom√°tico no Vercel:

```bash
# Deploy simples
npm run deploy:simple

# Deploy inteligente
npm run deploy:intelligent
```

### Vari√°veis de Ambiente no Vercel
Configure as vari√°veis no dashboard do Vercel ou via CLI:

```bash
vercel env add XAI_API_KEY
vercel env add XAI_MODEL
vercel env add XAI_MAX_TOKENS
vercel env add XAI_TEMPERATURE
```

## üîß Troubleshooting

### Problemas Comuns

1. **API Key inv√°lida**
   - Verifique se a key est√° correta no `.env`
   - Confirme que a key tem permiss√µes adequadas

2. **Streaming n√£o funciona**
   - Verifique se o navegador suporta ReadableStream
   - Confirme que n√£o h√° proxy bloqueando streaming

3. **Respostas lentas**
   - Ajuste o `XAI_MAX_TOKENS`
   - Verifique a lat√™ncia da rede
   - Considere usar cache para respostas comuns

### Debug

```bash
# Verificar configura√ß√£o
npm run config:validate

# Testar API diretamente
curl -X POST http://localhost:3000/api/chatbot-stream \
  -H "Content-Type: application/json" \
  -d '{"message": "Ol√°!"}'
```

## üìö Recursos Adicionais

- [Documenta√ß√£o xAI](https://docs.x.ai/)
- [AI SDK Documentation](https://sdk.vercel.ai/)
- [Vercel AI SDK Examples](https://github.com/vercel/ai)
- [Streaming API Guide](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API)

## ü§ù Contribui√ß√£o

Para contribuir com melhorias no chatbot:

1. Teste as funcionalidades em `/chatbot-test`
2. Implemente melhorias nos componentes
3. Adicione testes unit√°rios
4. Documente as mudan√ßas
5. Abra um Pull Request

---

**Desenvolvido para a Cl√≠nica Saraiva Vision** üè•üëÅÔ∏è